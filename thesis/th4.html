<!DOCTYPE html>
<html>
    <head>
        <title>Statistics</title>
        <meta http-equiv='cache-control' content='no-cache'> 
        <meta http-equiv='expires' content='0'> 
        <meta http-equiv='pragma' content='no-cache'>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
        <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>
    </head>
    <body>
        <h1>Th4: The Glivenko-Cantelli theorem, Proof, Simulations</h1>
        <h4>
            The Glivenko-Cantelli theorem is a fundamental result in probability theory that describes the convergence of the empirical distribution function to the true distribution function. <br>
            It is named after Valery Ivanovich Glivenko and Francesco Paolo Cantelli ². <br>
            The theorem states that the empirical distribution function converges uniformly almost surely to the theoretical distribution for a random variable X ∈ R ¹. <br>
            In other words, the difference between the empirical distribution function and the true distribution function approaches zero as the sample size increases ². <br>
            A constructive proof of the theorem is provided in ³. The proof is based on the concept of the Kolmogorov-Smirnov statistic, which measures the distance between the empirical distribution function and the true distribution function ¹. <br><br>
            The proof can be broken down into several steps. <br>
            First, we can apply the strong law of large numbers to the sequence I{Xi ≤ x}, i = 1, . . . n to assert that Fn(x) ˆ → F (x) a.s. <br>
            In this sense, Fn(x) ˆ is a reasonable estimate of F (x) for a given x ∈ R. But is Fn(x) ˆ a reasonable estimate of the F (x) when both are viewed as functions of x? The Glivenko-Cantelli theorem provides an answer to this question. <br>
            It asserts that the empirical distribution function converges uniformly almost surely to the theoretical distribution for a random variable X ∈ R ¹. In other words, <br>
            the difference between the empirical distribution function and the true distribution function approaches zero as the sample size increases ². <br>
            <br>
            Simulations can be used to illustrate the theorem. <br>
            For example, consider a sequence of i.i.d. random variables with a uniform distribution on the interval [0,1]. <br>
            The empirical distribution function can be computed for a sample of size n, and the difference between the empirical distribution function and the true distribution function can be plotted. <br>
            As the sample size increases, the difference between the two functions approaches zero, which is consistent with the Glivenko-Cantelli theorem ².<br>

            <hr>
            Some resources: <br>
            (1) Glivenko–Cantelli theorem - Wikipedia. https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem. <br>
            (2) 1 The Glivenko-Cantelli Theorem - University of Chicago. https://home.uchicago.edu/~amshaikh/webfiles/glivenko-cantelli.pdf. <br>
            (3) Constructive Proof of the Glivenko-Cantelli Theorem. https://arxiv.org/pdf/2110.13236v1.pdf.
        </h4>
        
    </body>
</html>