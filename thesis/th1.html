<!DOCTYPE html>
<html>
    <head>
        <title>Statistics</title>
        <meta http-equiv='cache-control' content='no-cache'> 
        <meta http-equiv='expires' content='0'> 
        <meta http-equiv='pragma' content='no-cache'>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    </head>
    <style>
        body{
            background-color: bisque;
            font-family:Arial, Helvetica, sans-serif;
        }
    </style>
    <body>
        <h1>Th1: The LLN Meaning, Proof, Simulations</h1>
        <h4>The Law of Large Numbers (LLN) is a theorem in probability theory that describes the result of performing the same experiment a large number of times. <br>
            According to the law, the average of the results obtained from a large number of trials should be close to the expected value and tends to become closer to the expected value as more trials are performed ². <br>
            A LLN is a proposition that provides a set of sufficient conditions for the convergence of the sample mean to a constant. <br>
            Typically, the constant is the expected value of the distribution from which the sample has been drawn. The sample mean is defined as the sum of the values of the random variables divided by the number of random variables. <br>
            A LLN states some conditions that are sufficient to guarantee the convergence of the sample mean to a constant, as the sample size increases. Typically, all the random variables in the sequence have the same expected value. <br>
            In this case, the constant to which the sample mean converges is the population mean ¹. <br><br>
            
            Chebyshev's Weak Law of Large Numbers is one of the best-known Weak Laws of Large Numbers (WLLNs). <br>
            It states that if a sequence of random variables is uncorrelated and covariance stationary, then a Weak Law of Large Numbers applies to the sample mean. <br>
            The sample mean converges in probability to the expected value of the distribution from which the sample has been drawn ¹. <br><br>
            
            A simulation that demonstrates LLN is the Monte Carlo simulation: 
            Monte Carlo simulation is a computational algorithm that uses repeated random sampling to obtain the probability of a range of outcomes. <br>
            It is a mathematical technique that is used to estimate the possible results of an uncertain event. Monte Carlo simulation is also known as the Monte Carlo method or multiple probability simulation ¹. <br>
            The Law of Large Numbers (LLN) is a theorem in probability theory that describes the result of performing the same experiment a large number of times. According to the law, the average of the results obtained from a large number of trials <br>
            should be close to the expected value and tends to become closer to the expected value as more trials are performed ². 
            Monte Carlo simulation can be used to demonstrate the LLN in action. <br>
            For example, suppose you want to estimate the value of π using Monte Carlo simulation. You can draw a square with side length 2 and inscribe a circle with radius 1 inside the square. <br> 
            The area of the square is 4, and the area of the circle is π. If you randomly generate points inside the square, the probability that a point will fall inside the circle is π/4. <br>
            By generating a large number of random points and counting the number of points that fall inside the circle, you can estimate the value of π. As the number of points generated increases, the estimate of π becomes more accurate, <br>
            which is an example of the LLN in action ³.<br><br>

            <hr>
            Some resources: <br>
            (1) Law of large numbers - Wikipedia. https://en.wikipedia.org/wiki/Law_of_large_numbers. <br>
            (2) Law of Large Numbers | Strong and weak, with proofs and exercises. https://www.statlect.com/asymptotic-theory/law-of-large-numbers. <br>
            (3) 17. LLN and CLT — Quantitative Economics with Julia. https://julia.quantecon.org/tools_and_techniques/lln_clt.html. <br>
            (1) Monte Carlo Simulation: A Hands-On Guide - neptune.ai. https://neptune.ai/blog/monte-carlo-simulation. <br>
            (2) What is Monte Carlo Simulation? | IBM. https://www.ibm.com/topics/monte-carlo-simulation. <br>
            (3) What Is Monte Carlo Simulation? - MATLAB & Simulink - MathWorks. https://in.mathworks.com/discovery/monte-carlo-simulation.html. <br>
            (4) GPU-Accelerated Monte Carlo Simulation for a Single-Photon ... - MDPI. https://www.mdpi.com/2072-4292/15/21/5245. </h4>
    </body>
</html>